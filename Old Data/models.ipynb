{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dca9fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb4f0dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Separate features and labels\\nX_train = train_df.drop(columns=[\\'is_fraud\\'])\\ny_train = train_df[\\'is_fraud\\']\\n\\nX_test = test_df.drop(columns=[\\'is_fraud\\'])\\ny_test = test_df[\\'is_fraud\\']\\n\\n# Display shapes for confirmation\\nprint(\"X_train shape:\", X_train.shape)\\nprint(\"y_train shape:\", y_train.shape)\\nprint(\"X_test shape:\", X_test.shape)\\nprint(\"y_test shape:\", y_test.shape)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(\"../datasets/fraudTrain.csv\")\n",
    "test_df = pd.read_csv(\"../datasets/fraudTest.csv\")\n",
    "\n",
    "# Drop ID column if it exists\n",
    "for df in [train_df, test_df]:\n",
    "    if 'id' in df.columns:\n",
    "        df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "'''\n",
    "# Separate features and labels\n",
    "X_train = train_df.drop(columns=['is_fraud'])\n",
    "y_train = train_df['is_fraud']\n",
    "\n",
    "X_test = test_df.drop(columns=['is_fraud'])\n",
    "y_test = test_df['is_fraud']\n",
    "\n",
    "# Display shapes for confirmation\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa543d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1296675, 2159)\n",
      "X_test shape: (555719, 2159)\n",
      "y_train shape: (1296675,)\n",
      "y_test shape: (555719,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Drop identifier and personal columns\n",
    "drop_cols = ['id', 'cc_num', 'first', 'last', 'trans_num', 'street', 'unix_time']\n",
    "train_df = train_df.drop(columns=[col for col in drop_cols if col in train_df.columns])\n",
    "test_df = test_df.drop(columns=[col for col in drop_cols if col in test_df.columns])\n",
    "\n",
    "# Convert datetime to time features\n",
    "for df in [train_df, test_df]:\n",
    "    df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "    df['dob'] = pd.to_datetime(df['dob'], errors='coerce')\n",
    "\n",
    "    # Compute age in years at time of transaction\n",
    "    df['age'] = (df['trans_date_trans_time'] - df['dob']).dt.days / 365.25\n",
    "    df['age'] = df['age'].fillna(df['age'].median())  # Handle any NaT values\n",
    "    \n",
    "    df['trans_hour'] = df['trans_date_trans_time'].dt.hour\n",
    "    df['trans_day'] = df['trans_date_trans_time'].dt.day\n",
    "    df['trans_weekday'] = df['trans_date_trans_time'].dt.weekday\n",
    "    df.drop(columns=['trans_date_trans_time', 'dob'], inplace=True)\n",
    "\n",
    "# Target variable\n",
    "y_train = train_df['is_fraud']\n",
    "y_test = test_df['is_fraud']\n",
    "\n",
    "# Drop target from features\n",
    "X_train = train_df.drop(columns=['is_fraud'])\n",
    "X_test = test_df.drop(columns=['is_fraud'])\n",
    "\n",
    "# Identify categorical and numeric columns\n",
    "categorical_cols = ['merchant', 'category', 'gender', 'job', 'city', 'state']\n",
    "numerical_cols = [col for col in X_train.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Final shape confirmation\n",
    "print(\"X_train shape:\", X_train_transformed.shape)\n",
    "print(\"X_test shape:\", X_test_transformed.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3095c056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      "[[553322    252]\n",
      " [  2116     29]]\n",
      "ROC AUC: 0.6622\n",
      "\n",
      "Decision Tree\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      "[[553066    508]\n",
      " [   461   1684]]\n",
      "ROC AUC: 0.8921\n",
      "\n",
      "Random Forest\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      "[[553541     33]\n",
      " [   914   1231]]\n",
      "ROC AUC: 0.9504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abeer\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py:158: UserWarning: [20:49:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Xgboost\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      "[[553416    158]\n",
      " [   537   1608]]\n",
      "ROC AUC: 0.9958\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --------------------------\n",
    "# Supervised Models\n",
    "# --------------------------\n",
    "models = {\n",
    "    \"logistic_regression\": LogisticRegression(max_iter=1000),\n",
    "    \"decision_tree\": DecisionTreeClassifier(),\n",
    "    \"random_forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"xgboost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_transformed, y_train)\n",
    "    y_pred = model.predict(X_test_transformed)\n",
    "    y_prob = model.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "    print(f\"\\n{name.replace('_', ' ').title()}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"ROC AUC:\", round(roc_auc_score(y_test, y_prob), 4))\n",
    "    \n",
    "    # Save the model\n",
    "    joblib.dump(model, f\"models/{name}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7789de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "------------------------------\n",
      "Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.10      0.01      0.02      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.55      0.51      0.51    555719\n",
      "weighted avg       0.99      1.00      0.99    555719\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "------------------------------\n",
      "Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.77      0.79      0.78      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.88      0.89      0.89    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "\n",
      "Random Forest\n",
      "------------------------------\n",
      "Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.57      0.72      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.99      0.79      0.86    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "\n",
      "Xgboost\n",
      "------------------------------\n",
      "Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.91      0.75      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.87      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test_transformed)\n",
    "    y_prob = model.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "    print(f\"\\n{name.replace('_', ' ').title()}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Report\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5521e431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio (PCA): 0.840798136415197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/pca_model.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Apply PCA\n",
    "# --------------------------\n",
    "pca = PCA(n_components=99, random_state=42)\n",
    "X_pca = pca.fit_transform(X_train_transformed)\n",
    "print(\"Explained Variance Ratio (PCA):\", pca.explained_variance_ratio_.sum())\n",
    "\n",
    "# Save PCA\n",
    "joblib.dump(pca, \"models/pca_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c021cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_PCA = pca.fit_transform(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "912f701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, true, pred, score_source=None):\n",
    "    acc = accuracy_score(true, pred)\n",
    "    auc = roc_auc_score(true, score_source if score_source is not None else pred)\n",
    "    print(f\"\\n{name} Evaluation\")\n",
    "    print(\"=\" * len(name))\n",
    "    print(\"Accuracy:\", round(acc, 4))\n",
    "    print(\"ROC AUC:\", round(auc, 4))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(true, pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a724a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Autoencoder]\n",
      "\u001b[1m17367/17367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 408us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1296675,99) (555719,99) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Predictions and evaluation\u001b[39;00m\n\u001b[0;32m     22\u001b[0m reconstructions \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mpredict(X_test_PCA)\n\u001b[1;32m---> 23\u001b[0m mse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mpower(\u001b[43mX_pca\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreconstructions\u001b[49m, \u001b[38;5;241m2\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m threshold \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(mse[y_test \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m95\u001b[39m)\n\u001b[0;32m     25\u001b[0m auto_preds \u001b[38;5;241m=\u001b[39m (mse \u001b[38;5;241m>\u001b[39m threshold)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1296675,99) (555719,99) "
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------\n",
    "# 1. Autoencoder on PCA Data\n",
    "# --------------------------\n",
    "print(\"\\n[Autoencoder]\")\n",
    "input_dim = X_pca.shape[1]\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(6, activation=\"relu\")(input_layer)\n",
    "encoder = Dense(3, activation=\"relu\")(encoder)\n",
    "decoder = Dense(6, activation=\"relu\")(encoder)\n",
    "decoder = Dense(input_dim, activation=\"sigmoid\")(decoder)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=1e-3), loss='mse')\n",
    "\n",
    "autoencoder.fit(X_pca, X_pca, epochs=20, batch_size=256, validation_split=0.2, shuffle=True, verbose=0)\n",
    "\n",
    "# Save Autoencoder\n",
    "autoencoder.save(\"models/autoencoder_pca_model.keras\")\n",
    "\n",
    "# Predictions and evaluation\n",
    "reconstructions = autoencoder.predict(X_test_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29cd7374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Autoencoder Evaluation\n",
      "===========\n",
      "Accuracy: 0.9483\n",
      "ROC AUC: 0.8052\n",
      "Confusion Matrix:\n",
      " [[525895  27679]\n",
      " [  1070   1075]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97    553574\n",
      "           1       0.04      0.50      0.07      2145\n",
      "\n",
      "    accuracy                           0.95    555719\n",
      "   macro avg       0.52      0.73      0.52    555719\n",
      "weighted avg       0.99      0.95      0.97    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mse = np.mean(np.power(X_test_PCA - reconstructions, 2), axis=1)\n",
    "threshold = np.percentile(mse[y_test == 0], 95)\n",
    "auto_preds = (mse > threshold).astype(int)\n",
    "\n",
    "evaluate_model(\"Autoencoder\", y_test, auto_preds, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67513380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DBSCAN]\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 2. DBSCAN on PCA Data\n",
    "# --------------------------\n",
    "print(\"\\n[DBSCAN]\")\n",
    "dbscan = DBSCAN(eps=1.5, min_samples=5)\n",
    "db_labels = dbscan.fit_predict(X_pca)\n",
    "binary_dbscan_labels = (db_labels == -1).astype(int)\n",
    "\n",
    "evaluate_model(\"DBSCAN\", y_train, binary_dbscan_labels)\n",
    "\n",
    "# Save DBSCAN model\n",
    "joblib.dump(dbscan, \"models/dbscan_pca_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19c68e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[KMeans]\n",
      "\n",
      "KMeans Evaluation\n",
      "======\n",
      "Accuracy: 0.3661\n",
      "ROC AUC: 0.5078\n",
      "Confusion Matrix:\n",
      " [[469846 819323]\n",
      " [  2619   4887]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.36      0.53   1289169\n",
      "           1       0.01      0.65      0.01      7506\n",
      "\n",
      "    accuracy                           0.37   1296675\n",
      "   macro avg       0.50      0.51      0.27   1296675\n",
      "weighted avg       0.99      0.37      0.53   1296675\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/kmeans_pca_model.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 3. KMeans on PCA Data\n",
    "# --------------------------\n",
    "print(\"\\n[KMeans]\")\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Flip label if needed\n",
    "if np.mean(y_train[kmeans_labels == 0]) > np.mean(y_train[kmeans_labels == 1]):\n",
    "    kmeans_labels = 1 - kmeans_labels\n",
    "\n",
    "evaluate_model(\"KMeans\", y_train, kmeans_labels)\n",
    "\n",
    "# Save KMeans model\n",
    "joblib.dump(kmeans, \"models/kmeans_pca_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1705f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# Example input dimension\n",
    "input_dim = X_train.shape[1]  # e.g., 99\n",
    "\n",
    "# Define model\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(64, activation='relu')(input_layer)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Training\n",
    "autoencoder.fit(X_train, X_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Predicting\n",
    "reconstructions = autoencoder.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
