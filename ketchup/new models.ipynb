{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b73503ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (4.13.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\abeer\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093b0755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      "[[83422  1873]\n",
      " [ 4139 81155]]\n",
      "ROC AUC: 0.9936\n",
      "\n",
      "Decision Tree\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      "[[85005   290]\n",
      " [  118 85176]]\n",
      "ROC AUC: 0.9976\n",
      "\n",
      "Random Forest\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      "[[85264    31]\n",
      " [    0 85294]]\n",
      "ROC AUC: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abeer\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py:158: UserWarning: [20:39:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Xgboost\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      "[[85242    53]\n",
      " [    0 85294]]\n",
      "ROC AUC: 1.0\n",
      "\n",
      "DBSCAN Clustering\n",
      "Unique Cluster Labels: [ -1   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16\n",
      "  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34\n",
      "  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52\n",
      "  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124\n",
      " 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178\n",
      " 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196\n",
      " 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214\n",
      " 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232\n",
      " 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250\n",
      " 251 252 253 254 255 256 257 258]\n",
      "\n",
      "Autoencoder Anomaly Detection\n",
      "Epoch 1/10\n",
      "\u001b[1m1244/1244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.9389 - val_loss: 0.7925\n",
      "Epoch 2/10\n",
      "\u001b[1m1244/1244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - loss: 0.7779 - val_loss: 0.7756\n",
      "Epoch 3/10\n",
      "\u001b[1m1244/1244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - loss: 0.7627 - val_loss: 0.7697\n",
      "Epoch 4/10\n",
      "\u001b[1m1244/1244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - loss: 0.7577 - val_loss: 0.7637\n",
      "Epoch 5/10\n",
      "\u001b[1m1244/1244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - loss: 0.7545 - val_loss: 0.7601\n",
      "Epoch 6/10\n",
      "\u001b[1m1244/1244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - loss: 0.7491 - val_loss: 0.7575\n",
      "Epoch 7/10\n",
      "\u001b[1m1244/1244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - loss: 0.7456 - val_loss: 0.7556\n",
      "Epoch 8/10\n",
      "\u001b[1m1244/1244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - loss: 0.7440 - val_loss: 0.7535\n",
      "Epoch 9/10\n",
      "\u001b[1m1244/1244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - loss: 0.7440 - val_loss: 0.7520\n",
      "Epoch 10/10\n",
      "\u001b[1m1244/1244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - loss: 0.7433 - val_loss: 0.7505\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=autoencoder_model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 89\u001b[0m\n\u001b[0;32m     86\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mfit(X_train, X_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Save Autoencoder\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mautoencoder_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m     92\u001b[0m reconstructions \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_api.py:114\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39msave_model_to_hdf5(\n\u001b[0;32m    112\u001b[0m         model, filepath, overwrite, include_optimizer\n\u001b[0;32m    113\u001b[0m     )\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filepath extension for saving. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease add either a `.keras` extension for the native Keras \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat (recommended) or a `.h5` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `model.export(filepath)` if you want to export a SavedModel \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor use with TFLite/TFServing/etc. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=autoencoder_model."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../datasets/creditcard_2023.csv\")\n",
    "\n",
    "if 'id' in df.columns:\n",
    "    df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, \"scaler.joblib\")\n",
    "\n",
    "# --------------------------\n",
    "# Supervised Models\n",
    "# --------------------------\n",
    "models = {\n",
    "    \"logistic_regression\": LogisticRegression(max_iter=1000),\n",
    "    \"decision_tree\": DecisionTreeClassifier(),\n",
    "    \"random_forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"xgboost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(f\"\\n{name.replace('_', ' ').title()}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"ROC AUC:\", round(roc_auc_score(y_test, y_prob), 4))\n",
    "    \n",
    "    # Save the model\n",
    "    joblib.dump(model, f\"{name}.joblib\")\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Autoencoder (Unsupervised)\n",
    "# --------------------------\n",
    "print(\"\\nAutoencoder Anomaly Detection\")\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 14\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
    "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "decoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "decoder = Dense(input_dim, activation=\"sigmoid\")(decoder)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=1e-3), loss='mse')\n",
    "\n",
    "autoencoder.fit(X_train, X_train, epochs=10, batch_size=256, shuffle=True, validation_split=0.2, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cea5321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5331/5331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 394us/step\n",
      "Confusion Matrix:\n",
      "[[81030  4265]\n",
      " [61601 23693]]\n",
      "ROC AUC: 0.6537\n"
     ]
    }
   ],
   "source": [
    "# Save Autoencoder\n",
    "autoencoder.save(\"autoencoder_model.keras\")\n",
    "\n",
    "# Evaluate\n",
    "reconstructions = autoencoder.predict(X_test)\n",
    "mse = np.mean(np.power(X_test - reconstructions, 2), axis=1)\n",
    "threshold = np.percentile(mse[y_test == 0], 95)\n",
    "preds = (mse > threshold).astype(int)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(\"ROC AUC:\", round(roc_auc_score(y_test, mse), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c444ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN Clustering (binary: noise vs. cluster)\n",
      "Cluster Counts: [542636  25994]\n",
      "Confusion Matrix:\n",
      "[[258321  25994]\n",
      " [284315      0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.91      0.62    284315\n",
      "           1       0.00      0.00      0.00    284315\n",
      "\n",
      "    accuracy                           0.45    568630\n",
      "   macro avg       0.24      0.45      0.31    568630\n",
      "weighted avg       0.24      0.45      0.31    568630\n",
      "\n",
      "ROC AUC Score: 0.4543\n"
     ]
    }
   ],
   "source": [
    "# Convert to binary: 0 = cluster (legit), 1 = noise (possible fraud)\n",
    "binary_labels = (dbscan_labels == -1).astype(int)\n",
    "\n",
    "print(\"DBSCAN Clustering (binary: noise vs. cluster)\")\n",
    "print(\"Cluster Counts:\", np.bincount(binary_labels))\n",
    "\n",
    "# Evaluate against actual labels if available\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, binary_labels))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y, binary_labels))\n",
    "print(\"ROC AUC Score:\", round(roc_auc_score(y, binary_labels), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e66c9512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DBSCAN Clustering\n",
      "Unique Cluster Labels: [-1  0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['dbscan_model.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------\n",
    "# DBSCAN (Unsupervised)\n",
    "# --------------------------\n",
    "print(\"\\nDBSCAN Clustering\")\n",
    "dbscan = DBSCAN(eps=2, min_samples=500)\n",
    "dbscan_labels = dbscan.fit_predict(X_scaled)\n",
    "print(\"Unique Cluster Labels:\", np.unique(dbscan_labels))\n",
    "\n",
    "# Save DBSCAN\n",
    "joblib.dump(dbscan, \"dbscan_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b19e218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN Clustering (binary: noise vs. cluster)\n",
      "Cluster Counts: [420113 148517]\n",
      "Confusion Matrix:\n",
      "[[170154 114161]\n",
      " [249959  34356]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.60      0.48    284315\n",
      "           1       0.23      0.12      0.16    284315\n",
      "\n",
      "    accuracy                           0.36    568630\n",
      "   macro avg       0.32      0.36      0.32    568630\n",
      "weighted avg       0.32      0.36      0.32    568630\n",
      "\n",
      "ROC AUC Score: 0.3597\n"
     ]
    }
   ],
   "source": [
    "# Convert to binary: 0 = cluster (legit), 1 = noise (possible fraud)\n",
    "binary_labels = (dbscan_labels == -1).astype(int)\n",
    "\n",
    "print(\"DBSCAN Clustering (binary: noise vs. cluster)\")\n",
    "print(\"Cluster Counts:\", np.bincount(binary_labels))\n",
    "\n",
    "# Evaluate against actual labels if available\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, binary_labels))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y, binary_labels))\n",
    "print(\"ROC AUC Score:\", round(roc_auc_score(y, binary_labels), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2b9282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the scaler and models\n",
    "scaler = joblib.load(\"scaler.joblib\")\n",
    "logistic_model = joblib.load(\"logistic_regression.joblib\")\n",
    "decision_tree_model = joblib.load(\"decision_tree.joblib\")\n",
    "random_forest_model = joblib.load(\"random_forest.joblib\")\n",
    "xgboost_model = joblib.load(\"xgboost.joblib\")\n",
    "dbscan_model = joblib.load(\"dbscan_model.joblib\")\n",
    "autoencoder_model = load_model(\"autoencoder_model\")\n",
    "\n",
    "# Load new or test data\n",
    "df = pd.read_csv(\"creditcard_2023.csv\")\n",
    "if 'id' in df.columns:\n",
    "    df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# --- Supervised Models Prediction ---\n",
    "models = {\n",
    "    \"Logistic Regression\": logistic_model,\n",
    "    \"Decision Tree\": decision_tree_model,\n",
    "    \"Random Forest\": random_forest_model,\n",
    "    \"XGBoost\": xgboost_model,\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_scaled)\n",
    "    y_prob = model.predict_proba(X_scaled)[:, 1]\n",
    "    \n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"-\" * len(name))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y, y_pred))\n",
    "    print(\"ROC AUC Score:\", round(roc_auc_score(y, y_prob), 4))\n",
    "\n",
    "# --- DBSCAN Clustering (Unsupervised) ---\n",
    "print(\"\\nDBSCAN Clustering\")\n",
    "dbscan_labels = dbscan_model.fit_predict(X_scaled)\n",
    "print(\"Cluster Labels:\", np.unique(dbscan_labels))\n",
    "\n",
    "# --- Autoencoder (Unsupervised) ---\n",
    "print(\"\\nAutoencoder Anomaly Detection\")\n",
    "reconstructions = autoencoder_model.predict(X_scaled)\n",
    "mse = np.mean(np.power(X_scaled - reconstructions, 2), axis=1)\n",
    "\n",
    "# Threshold (recomputed or hardcoded — example below)\n",
    "threshold = np.percentile(mse[y == 0], 95)\n",
    "preds = (mse > threshold).astype(int)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, preds))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y, preds))\n",
    "print(\"ROC AUC Score:\", round(roc_auc_score(y, mse), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
